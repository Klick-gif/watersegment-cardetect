import warnings
warnings.filterwarnings('ignore')
from fastapi import FastAPI, File, UploadFile, HTTPException, Form, Query
from fastapi.responses import HTMLResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi import Request
from pydantic import BaseModel
import os
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import io
import json
from ultralytics import YOLO
import uuid
from typing import List, Dict, Any
import shutil
import torch
from transformers import DetrImageProcessor, DetrForObjectDetection

# CPUä¼˜åŒ–é…ç½®
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # å¼ºåˆ¶ä½¿ç”¨CPU
torch.set_num_threads(1)  # é™åˆ¶çº¿ç¨‹æ•°ä»¥ä¼˜åŒ–CPUæ€§èƒ½

# ä¿®å¤PyTorch 2.6çš„weights_onlyé—®é¢˜
def safe_torch_load(file_path):
    """å®‰å…¨åŠ è½½PyTorchæ¨¡å‹æ–‡ä»¶ï¼Œå…¼å®¹PyTorch 2.6"""
    try:
        # é¦–å…ˆå°è¯•weights_only=Trueï¼ˆå®‰å…¨æ¨¡å¼ï¼‰
        return torch.load(file_path, weights_only=True, map_location='cpu')
    except Exception as e:
        print(f"å®‰å…¨æ¨¡å¼åŠ è½½å¤±è´¥: {e}ï¼Œå°è¯•éå®‰å…¨æ¨¡å¼")
        # å¦‚æœå®‰å…¨æ¨¡å¼å¤±è´¥ï¼Œä½¿ç”¨éå®‰å…¨æ¨¡å¼ï¼ˆä»…å¯¹å¯ä¿¡æ–‡ä»¶ä½¿ç”¨ï¼‰
        return torch.load(file_path, weights_only=False, map_location='cpu')

app = FastAPI(title="ç§¯æ°´è¯†åˆ«å’Œè½¦è¾†æ·¹æ²¡éƒ¨ä½åˆ¤åˆ«ç³»ç»Ÿ - ä¿®å¤ç‰ˆ")

# åˆ›å»ºå¿…è¦çš„ç›®å½•
os.makedirs("uploads", exist_ok=True)
os.makedirs("results", exist_ok=True)
os.makedirs("templates", exist_ok=True)

# æŒ‚è½½é™æ€æ–‡ä»¶
app.mount("/results", StaticFiles(directory="results"), name="results")

# æ¨¡æ¿é…ç½®
templates = Jinja2Templates(directory="templates")

# æ¨¡å‹é…ç½®ï¼ˆä¿®å¤ç‰ˆï¼‰
MODELS = {
    "detect": {
        "name": "YOLO11",
        "path": "detect/yolo11_best.pt",
        "type": "detect"
    },
    "detr": {
        "name": "DETR",
        "path": "detect/detr_recnet50",
        "type": "detect"
    },
    "segment": {
        "name": "YOLO11_seg", 
        "path": "segment/yolo11_best.pt",
        "type": "segment"
    },
    "segnet": {
        "name": "segNet",
        "path": "segment/best.pth",
        "type": "segment"
    }
}

# è½¦è¾†æ·¹æ²¡éƒ¨ä½ç±»åˆ«æ˜ å°„
VEHICLE_PARTS = {
    0: "è½¦çª—",
    1: "è½¦é—¨",
    2: "è½¦è½®",
}

# è¯·æ±‚æ¨¡å‹
class PredictRequest(BaseModel):
    file_id: str
    model_type: str = "detect"
    confidence: float = 0.60

@app.get("/", response_class=HTMLResponse)
async def read_root(request: Request):
    """ä¸»é¡µé¢"""
    return templates.TemplateResponse("index.html", {"request": request, "models": MODELS})

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {"status": "healthy", "device": "cpu", "pytorch_version": torch.__version__}

@app.post("/upload")
async def upload_image(file: UploadFile = File(...)):
    """ä¸Šä¼ å›¾ç‰‡"""
    if not file.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="åªæ”¯æŒå›¾ç‰‡æ–‡ä»¶")
    
    # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
    file_id = str(uuid.uuid4())
    file_extension = os.path.splitext(file.filename)[1]
    filename = f"{file_id}{file_extension}"
    file_path = os.path.join("uploads", filename)
    
    # ä¿å­˜æ–‡ä»¶
    with open(file_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    
    return {"file_id": file_id, "filename": filename, "message": "å›¾ç‰‡ä¸Šä¼ æˆåŠŸ"}

@app.post("/predict")
async def predict_image(request: PredictRequest):
    """å›¾åƒé¢„æµ‹ï¼ˆä¿®å¤ç‰ˆï¼‰"""
    try:
        # ä»è¯·æ±‚ä¸­è·å–å‚æ•°
        file_id = request.file_id
        model_type = request.model_type
        confidence = request.confidence
        
        print(f"æ”¶åˆ°é¢„æµ‹è¯·æ±‚: file_id={file_id}, model_type={model_type}, confidence={confidence}")
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"è¿è¡Œè®¾å¤‡: CPU")
        
        # æŸ¥æ‰¾ä¸Šä¼ çš„æ–‡ä»¶
        upload_dir = "uploads"
        files = os.listdir(upload_dir)
        input_file = None
        for f in files:
            if f.startswith(file_id):
                input_file = os.path.join(upload_dir, f)
                break
        
        if not input_file or not os.path.exists(input_file):
            raise HTTPException(status_code=404, detail="æ‰¾ä¸åˆ°ä¸Šä¼ çš„æ–‡ä»¶")
        
        # åŠ è½½æ¨¡å‹
        if model_type not in MODELS:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹")
        
        model_path = MODELS[model_type]["path"]
        if not os.path.exists(model_path):
            raise HTTPException(status_code=404, detail="æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")

        yolo_name = f"{file_id}_{model_type}"
        base_dir = f"results/{file_id}_{model_type}"
        result_dir = base_dir
        index = 1
        while os.path.exists(result_dir):
            yolo_name = f"{yolo_name}_{index}"
            result_dir = f"{base_dir}_{index}"
            index += 1

        os.makedirs(result_dir)
        
        if model_type == "detect" or model_type == "segment":
            try:
                # ä¿®å¤YOLOæ¨¡å‹åŠ è½½
                model = YOLO(model_path)
                
                # è¿›è¡Œé¢„æµ‹ï¼ˆCPUä¼˜åŒ–å‚æ•°ï¼‰
                results = model.predict(
                    source=input_file,
                    conf=confidence,
                    save=True,
                    project="results",
                    name=yolo_name,
                    exist_ok=True,
                    device='cpu',  # å¼ºåˆ¶ä½¿ç”¨CPU
                    verbose=False  # å‡å°‘æ—¥å¿—è¾“å‡º
                )
                
                # å¤„ç†ç»“æœ
                result_data = []
                vehicle_stats = {}
                
                for r in results:
                    if r.boxes is not None:
                        for box in r.boxes:
                            cls = int(box.cls[0])
                            conf = float(box.conf[0])
                            xyxy = box.xyxy[0].cpu().numpy()
                            result_data.append({
                                "class_id": cls,
                                "class_name": VEHICLE_PARTS.get(cls, f"ç±»åˆ«{cls}") if model_type == 'detect' else 'æ°´é¢',
                                "confidence": conf,
                                "bbox": xyxy.tolist()
                            })
                            
                            # ç»Ÿè®¡è½¦è¾†éƒ¨ä½
                            part_name = VEHICLE_PARTS.get(cls, f"ç±»åˆ«{cls}") if model_type == 'detect' else 'æ°´é¢'
                            if part_name not in vehicle_stats:
                                vehicle_stats[part_name] = 0
                            vehicle_stats[part_name] += 1
                
            except Exception as e:
                print(f"YOLOæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                raise HTTPException(status_code=500, detail=f"YOLOæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            
        elif model_type == "detr":
            try:
                # DETRæ¨¡å‹é¢„æµ‹é€»è¾‘ï¼ˆä¿®å¤ç‰ˆï¼‰
                device = torch.device("cpu")
                
                # ä¿®å¤DETRæ¨¡å‹åŠ è½½
                processor = DetrImageProcessor.from_pretrained(model_path, local_files_only=True)
                
                # ä½¿ç”¨å®‰å…¨çš„æ¨¡å‹åŠ è½½æ–¹å¼
                model = DetrForObjectDetection.from_pretrained(
                    model_path, 
                    local_files_only=True,
                    torch_dtype=torch.float32
                )
                model.to(device)
                model.eval()
                print(f"æˆåŠŸåŠ è½½æœ¬åœ°DETRæ¨¡å‹åˆ°CPU: {model_path}")
                
                # åŠ è½½å›¾åƒ
                image = Image.open(input_file).convert('RGB')
                
                # è¿›è¡Œé¢„æµ‹
                with torch.no_grad():
                    inputs = processor(images=image, return_tensors="pt").to(device)
                    outputs = model(**inputs)
                
                # åå¤„ç†
                target_sizes = torch.tensor([image.size[::-1]]).to(device)
                results = processor.post_process_object_detection(
                    outputs, target_sizes=target_sizes, threshold=confidence
                )[0]
                
                # è§£æç»“æœ
                boxes = results['boxes'].cpu().numpy()
                scores = results['scores'].cpu().numpy()
                labels = results['labels'].cpu().numpy()
                
                # DETRç±»åˆ«åç§°æ˜ å°„
                detr_class_names = ['è½¦çª—', 'è½¦é—¨', 'è½¦è½®']
                
                # å¤„ç†ç»“æœ
                result_data = []
                vehicle_stats = {}
                
                for box, score, label in zip(boxes, scores, labels):
                    if score >= confidence:
                        x_min, y_min, x_max, y_max = box
                        class_name = detr_class_names[label] if label < len(detr_class_names) else f"ç±»åˆ«{label}"
                        
                        result_data.append({
                            "class_id": int(label),
                            "class_name": class_name,
                            "confidence": float(score),
                            "bbox": [float(x_min), float(y_min), float(x_max), float(y_max)]
                        })
                        
                        if class_name not in vehicle_stats:
                            vehicle_stats[class_name] = 0
                        vehicle_stats[class_name] += 1
                
                # åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
                draw = ImageDraw.Draw(image)
                colors = ['red', 'blue', 'green', 'yellow', 'purple', 'orange']
                
                try:
                    font = ImageFont.truetype("MSYH.ttc", 100)
                except:
                    font = ImageFont.load_default()
                
                for i, (box, score, label) in enumerate(zip(boxes, scores, labels)):
                    if score >= confidence:
                        x_min, y_min, x_max, y_max = box
                        class_name = detr_class_names[label] if label < len(detr_class_names) else f"ç±»åˆ«{label}"
                        color = colors[label % len(colors)]
                        
                        # ç»˜åˆ¶è¾¹ç•Œæ¡†
                        draw.rectangle([x_min, y_min, x_max, y_max], outline=color, width=3)
                        
                        # ç»˜åˆ¶æ ‡ç­¾
                        label_text = f"{class_name}: {score:.2f}"
                        try:
                            bbox = draw.textbbox((x_min, y_min), label_text, font=font)
                            draw.rectangle(bbox, fill=color)
                            draw.text((x_min, y_min), label_text, fill="white", font=font)
                        except:
                            draw.text((x_min, y_min), label_text, fill=color)
                
                # ä¿å­˜ç»“æœå›¾åƒ
                result_image_path = os.path.join(result_dir, f"{file_id}_{model_type}.jpg")
                image.save(result_image_path)
                print(f"DETRé¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {result_image_path}")
                
            except Exception as e:
                print(f"DETRæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                raise HTTPException(status_code=500, detail=f"DETRæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        
        elif model_type == "segnet":
            try:
                # ä¿®å¤segNetæ¨¡å‹åŠ è½½
                from segNet.test_fixed import WaterSegmentationPredictor
                
                # ä¿®æ”¹segNetçš„æ¨¡å‹åŠ è½½æ–¹å¼
                predictor = WaterSegmentationPredictor(model_path)
                mask, original_image, prob = predictor.predict(input_file, confidence)
                result_image_path = os.path.join(result_dir, f"{file_id}_{model_type}.jpg")
                
                if float(prob) < float(confidence):
                    cv2.imwrite(result_image_path, original_image)
                    result_data = []
                    vehicle_stats = {"æ°´é¢": 0}
                    print(f"segNetä½äºé˜ˆå€¼(ç½®ä¿¡åº¦={prob:.2f} < é˜ˆå€¼={confidence:.2f})ï¼Œå·²ä¿å­˜åŸå›¾: {result_image_path}")
                else:
                    # åˆ›å»ºå½©è‰²maskå¹¶å åŠ 
                    colored_mask = np.zeros_like(original_image)
                    colored_mask[mask > 0] = [0, 255, 0]
                    overlay = original_image.copy()
                    overlay[mask > 0] = cv2.addWeighted(original_image, 0.7, colored_mask, 0.3, 0)[mask > 0]
                    
                    label_text = f"æ°´é¢: {float(prob):.2f}"
                    overlay_pil = Image.fromarray(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))
                    draw = ImageDraw.Draw(overlay_pil)
                    try:
                        font = ImageFont.truetype("MSYH.ttc", 100)
                    except:
                        font = ImageFont.load_default()
                    draw.text((10, 30), label_text, font=font, fill=(0, 255, 0))
                    overlay = cv2.cvtColor(np.array(overlay_pil), cv2.COLOR_RGB2BGR)
                    cv2.imwrite(result_image_path, overlay)
                    
                    result_data = [{
                        "class_id": 0,
                        "class_name": "æ°´é¢",
                        "confidence": float(prob),
                    }]
                    
                    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask.astype(np.uint8))
                    water_areas = []
                    for label in range(1, num_labels):
                        area = stats[label, cv2.CC_STAT_AREA]
                        if area > 100:
                            water_areas.append(area)
                    vehicle_stats = {"æ°´é¢": len(water_areas)}
                    print(f"segNeté¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {result_image_path}")
                    
            except Exception as e:
                print(f"segNetæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                raise HTTPException(status_code=500, detail=f"segNetæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        
        else:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹")
        
        # æŸ¥æ‰¾ç»“æœå›¾ç‰‡
        result_image = ""
        if os.path.exists(result_dir):
            for file in os.listdir(result_dir):
                if file.endswith(('.jpg', '.png', '.jpeg')):
                    result_image = f"/{result_dir}/{file}"
                    break
        
        return {
            "success": True,
            "file_id": file_id,
            "model_type": model_type,
            "result_dir": result_dir,
            "detections": result_data,
            "vehicle_stats": vehicle_stats,
            "result_image": result_image,
            "total_detections": len(result_data),
            "device": "cpu",
            "pytorch_version": torch.__version__
        }
        
    except Exception as e:
        print(f"é¢„æµ‹å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"é¢„æµ‹å¤±è´¥: {str(e)}")

# å…¶ä»–ç«¯ç‚¹ä¿æŒä¸å˜...
@app.get("/download")
async def download_result(result_dir: str = Query(...)):
    """ä¸‹è½½ç»“æœå›¾ç‰‡"""
    if not os.path.exists(result_dir):
        raise HTTPException(status_code=404, detail="ç»“æœç›®å½•ä¸å­˜åœ¨")
    
    result_files = []
    for file in os.listdir(result_dir):
        if file.endswith(('.jpg', '.png', '.jpeg')):
            result_files.append(file)
    
    if not result_files:
        raise HTTPException(status_code=404, detail="æ²¡æœ‰æ‰¾åˆ°ç»“æœå›¾ç‰‡")
    
    result_file = os.path.join(result_dir, result_files[0])
    return FileResponse(
        result_file,
        media_type='application/octet-stream',
        filename=f"result_{os.path.basename(result_file)}"
    )

@app.get("/download_original/{file_id}")
async def download_original(file_id: str):
    """ä¸‹è½½åŸå§‹å›¾ç‰‡"""
    upload_dir = "uploads"
    files = os.listdir(upload_dir)
    original_file = None
    
    for f in files:
        if f.startswith(file_id):
            original_file = os.path.join(upload_dir, f)
            break
    
    if not original_file or not os.path.exists(original_file):
        raise HTTPException(status_code=404, detail="åŸå§‹æ–‡ä»¶ä¸å­˜åœ¨")
    
    return FileResponse(
        original_file,
        media_type='application/octet-stream',
        filename=f"original_{file_id}.jpg"
    )

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ å¯åŠ¨ç§¯æ°´è¯†åˆ«ç³»ç»Ÿ - ä¿®å¤ç‰ˆ")
    print("ğŸ“± è®¿é—®åœ°å€: http://localhost:8000")
    print("ğŸ“š APIæ–‡æ¡£: http://localhost:8000/docs")
    print("ğŸ’» è¿è¡Œè®¾å¤‡: CPU")
    print(f"ğŸ”¥ PyTorchç‰ˆæœ¬: {torch.__version__}")
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")